# PrzykÅ‚ady TensorFlow C++ - Przewodnik dla StudentÃ³w

## Wprowadzenie

Ten katalog zawiera przykÅ‚ady wykorzystania TensorFlow API w jÄ™zyku C++. JeÅ›li szukasz innych zasobÃ³w, sprawdÅº:

* **PrzykÅ‚ady Python TensorFlow** - zobacz [samouczki na tensorflow.org](https://tensorflow.org/tutorials)
* **PrzykÅ‚ady Keras** - zobacz [keras.io/examples](https://keras.io/examples/)
* **PrzykÅ‚ady TensorFlow Lite** - zobacz [repozytorium tensorflow/examples](https://github.com/tensorflow/examples/tree/master/lite)
* **Notatniki kursu Udacity** - zobacz [ten katalog](https://github.com/tensorflow/examples/tree/master/courses)

## O tych przykÅ‚adach

âš ï¸ **WaÅ¼ne informacje:**

* API C++ TensorFlow moÅ¼na Å‚atwo budowaÄ‡ tylko w ramach systemu budowania `bazel` TensorFlow. JeÅ›li potrzebujesz samodzielnej kompilacji, zobacz [C API](https://www.tensorflow.org/install/lang_c).
* Ten katalog nie jest aktywnie utrzymywany - przykÅ‚ady mogÄ… byÄ‡ przestarzaÅ‚e.

**Dla wiÄ™kszoÅ›ci projektÃ³w zalecamy uÅ¼ywanie API Python**, ktÃ³re jest bardziej kompletne i Å‚atwiejsze w uÅ¼yciu.

## DostÄ™pne przykÅ‚ady

### 1. Rozpoznawanie obrazÃ³w (label_image)

ğŸ“ **Katalog:** `label_image/`

**Co robi:**
- Klasyfikuje obiekty na obrazach
- UÅ¼ywa modelu Inception V3
- Rozpoznaje 1000 kategorii obiektÃ³w

**Dlaczego jest waÅ¼ny dla robotyki:**
- Robot moÅ¼e rozpoznawaÄ‡ przedmioty w swoim otoczeniu
- Podstawa dla systemÃ³w widzenia komputerowego
- Przydatny do nawigacji i manipulacji obiektami

**Dokumentacja:**
- [README_PL.md](label_image/README_PL.md) - SzczegÃ³Å‚owy przewodnik po polsku
- [README.md](label_image/README.md) - Oryginalna dokumentacja

**Jak uruchomiÄ‡:**
```bash
# Python
python3 label_image.py --image=moj_obraz.jpg

# C++ (wymaga bazel)
bazel run label_image -- --image=moj_obraz.jpg
```

**Zastosowanie dla Unitree G1:**
- Rozpoznawanie obiektÃ³w do manipulacji
- Identyfikacja przeszkÃ³d
- Rozpoznawanie osÃ³b

### 2. Rozpoznawanie poleceÅ„ gÅ‚osowych (speech_commands)

ğŸ“ **Katalog:** `speech_commands/`

**Co robi:**
- Rozpoznaje krÃ³tkie komendy gÅ‚osowe
- MoÅ¼na trenowaÄ‡ na wÅ‚asnych sÅ‚owach (rÃ³wnieÅ¼ po polsku!)
- DziaÅ‚a w czasie rzeczywistym

**Dlaczego jest waÅ¼ny dla robotyki:**
- Robot moÅ¼e reagowaÄ‡ na polecenia gÅ‚osowe
- Sterowanie bez uÅ¼ycia rÄ…k
- Naturalna interakcja czÅ‚owiek-robot

**Dokumentacja:**
- [README_PL.md](speech_commands/README_PL.md) - Kompletny przewodnik po polsku
- [README.md](speech_commands/README.md) - Oryginalna dokumentacja

**Jak uruchomiÄ‡:**
```bash
# Trening modelu
python3 train.py --wanted_words=idz,stop,lewo,prawo

# Testowanie
python3 label_wav.py --wav=test.wav
```

**Zastosowanie dla Unitree G1:**
- Sterowanie ruchem robota gÅ‚osem
- Polecenia manipulatora
- Interakcja z uÅ¼ytkownikiem

### 3. Tworzenie wÅ‚asnych operacji (adding_an_op)

ğŸ“ **Katalog:** `adding_an_op/`

**Co robi:**
- Pokazuje jak tworzyÄ‡ wÅ‚asne operacje TensorFlow
- PrzykÅ‚ady w C++ i Python
- Integracja z GPU (CUDA)

**Dlaczego jest waÅ¼ny:**
- Optymalizacja wydajnoÅ›ci dla specyficznych zadaÅ„
- Implementacja niestandardowych algorytmÃ³w
- Rozszerzanie moÅ¼liwoÅ›ci TensorFlow

**Dokumentacja:**
- [README.md](adding_an_op/README.md) - Przewodnik tworzenia operacji

**Dla kogo:**
- Zaawansowani uÅ¼ytkownicy
- Optymalizacja wydajnoÅ›ci krytycznych czÄ™Å›ci kodu

### 4. WÅ‚asne operacje - dokumentacja (custom_ops_doc)

ğŸ“ **Katalog:** `custom_ops_doc/`

**Co zawiera:**
- SzczegÃ³Å‚owe przykÅ‚ady tworzenia wÅ‚asnych operacji
- RÃ³Å¼ne poziomy zÅ‚oÅ¼onoÅ›ci (multiplex_1, multiplex_2, etc.)
- Integracja z gradientami (backward pass)

**Podkatalogi:**
- `multiplex_1/` - Podstawowa operacja
- `multiplex_2/` - Z gradienty
- `multiplex_3/` - Z shape inference
- `multiplex_4/` - PeÅ‚na implementacja
- `simple_hash_table/` - Implementacja hash table
- `sleep/` - Operacja asynchroniczna

### 5. Inne przykÅ‚ady

#### Przetwarzanie audio (wav_to_spectrogram)
- Konwersja plikÃ³w WAV do spektrogramÃ³w
- UÅ¼yteczne dla dalszej analizy audio

#### Ponowne trenowanie modeli (image_retraining)
- Transfer learning dla wÅ‚asnych danych
- Dostosowanie pretrained modeli

#### Android
- Integracja TensorFlow na urzÄ…dzeniach Android
- TensorFlow Lite dla aplikacji mobilnych

## Struktura katalogÃ³w

```
tensorflow/examples/
â”œâ”€â”€ README_PL.md                    # Ten plik
â”œâ”€â”€ README.md                       # Oryginalna dokumentacja
â”‚
â”œâ”€â”€ label_image/                    # Rozpoznawanie obrazÃ³w â­
â”‚   â”œâ”€â”€ README_PL.md
â”‚   â”œâ”€â”€ label_image.py             # Wersja Python (z komentarzami PL)
â”‚   â””â”€â”€ main.cc                     # Wersja C++
â”‚
â”œâ”€â”€ speech_commands/                # Rozpoznawanie mowy â­
â”‚   â”œâ”€â”€ README_PL.md
â”‚   â”œâ”€â”€ train.py                    # Trenowanie modelu (z komentarzami PL)
â”‚   â”œâ”€â”€ label_wav.py               # Testowanie
â”‚   â””â”€â”€ freeze.py                   # Tworzenie wersji produkcyjnej
â”‚
â”œâ”€â”€ adding_an_op/                   # WÅ‚asne operacje
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ custom_ops_doc/                 # Dokumentacja wÅ‚asnych operacji
â”‚   â”œâ”€â”€ multiplex_1/
â”‚   â”œâ”€â”€ multiplex_2/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ wav_to_spectrogram/            # Przetwarzanie audio
â”œâ”€â”€ image_retraining/              # Transfer learning
â”œâ”€â”€ android/                        # PrzykÅ‚ady Android
â””â”€â”€ udacity/                        # MateriaÅ‚y kursu Udacity
```

## Rekomendowane Å›cieÅ¼ki nauki

### Dla poczÄ…tkujÄ…cych (2-4 tygodnie)

```
TydzieÅ„ 1-2: Podstawy
â”œâ”€ Zapoznanie z TensorFlow Python API
â”œâ”€ PrzejÅ›cie przez tutorial label_image
â”‚  â””â”€ Uruchomienie na wÅ‚asnych obrazach
â””â”€ Zrozumienie kodu z komentarzami

TydzieÅ„ 3-4: Pierwszy projekt
â”œâ”€ Trening modelu speech_commands
â”œâ”€ Zbieranie wÅ‚asnych danych
â””â”€ Testowanie na prawdziwych danych
```

### Dla Å›rednio zaawansowanych (4-8 tygodni)

```
TydzieÅ„ 1-3: Vision
â”œâ”€ Transfer learning z image_retraining
â”œâ”€ Fine-tuning na wÅ‚asnych danych
â””â”€ Integracja z robotem (symulacja)

TydzieÅ„ 4-6: Speech
â”œâ”€ Trening na polskich komendach
â”œâ”€ Optymalizacja dla czasu rzeczywistego
â””â”€ Integracja z mikrofonami robota

TydzieÅ„ 7-8: Integracja
â”œâ”€ ÅÄ…czenie vision + speech
â”œâ”€ Deployment na robocie
â””â”€ End-to-end testing
```

### Dla zaawansowanych (8+ tygodni)

```
â”œâ”€ WÅ‚asne architektury sieci
â”œâ”€ Implementacja custom operations
â”œâ”€ Multi-task learning
â”œâ”€ Reinforcement learning
â””â”€ Research & publikacje
```

## Praca z robotem Unitree G1 EDU-U6

### Typowy workflow projektu

```
1. DEVELOPMENT (na komputerze)
   â”œâ”€ Zbierz dane z robota
   â”œâ”€ Wytrenuj model
   â””â”€ Przetestuj offline

2. OPTIMIZATION
   â”œâ”€ Konwertuj do TensorFlow Lite
   â”œâ”€ Kwantyzacja
   â””â”€ Benchmark wydajnoÅ›ci

3. DEPLOYMENT (na robocie)
   â”œâ”€ Transfer modelu
   â”œâ”€ Integracja z SDK robota
   â””â”€ Testowanie w realnym Å›rodowisku

4. MONITORING & IMPROVEMENT
   â”œâ”€ Zbieraj nowe dane
   â”œâ”€ Retrain model
   â””â”€ Deploy aktualizacji
```

### PrzykÅ‚adowa integracja

```python
# Pseudo-kod integracji TensorFlow z robotem
import unitree_sdk
import tensorflow as tf

# Inicjalizacja robota
robot = unitree_sdk.G1Robot()

# ZaÅ‚aduj modele TensorFlow
vision_model = tf.lite.Interpreter("object_detector.tflite")
speech_model = tf.lite.Interpreter("speech_commands.tflite")

# GÅ‚Ã³wna pÄ™tla robota
while robot.is_active():
    # Percepcja
    image = robot.camera.capture()
    audio = robot.microphone.record()
    
    # Analiza TensorFlow
    objects = vision_model.detect(image)
    command = speech_model.recognize(audio)
    
    # Reakcja robota
    if command == "podnieÅ›" and "kubek" in objects:
        robot.pick_up_object("kubek")
    
    elif command == "idÅº":
        robot.move_forward()
    
    # ...etc
```

## NarzÄ™dzia pomocnicze

### Do developmentu
- **Visual Studio Code** - Z rozszerzeniem Python
- **PyCharm** - IDE dla Pythona
- **Jupyter Notebooks** - Interaktywne eksperymenty
- **Google Colab** - Darmowe GPU do treningu

### Do wizualizacji
- **TensorBoard** - Monitoring treningu
- **Matplotlib** - Wykresy i wizualizacje
- **OpenCV** - Przetwarzanie obrazÃ³w

### Do zarzÄ…dzania danymi
- **LabelImg** - Annotacja obrazÃ³w
- **Audacity** - Edycja audio
- **Roboflow** - ZarzÄ…dzanie datasetami

## Troubleshooting

### Problem: Nie mogÄ™ skompilowaÄ‡ przykÅ‚adÃ³w C++

**RozwiÄ…zanie:**
- UÅ¼yj wersji Python (zazwyczaj wystarczajÄ…ca)
- JeÅ›li musisz C++, zobacz [C API documentation](https://www.tensorflow.org/install/lang_c)
- RozwaÅ¼ TensorFlow Lite C++ API (lÅ¼ejsze)

### Problem: PrzykÅ‚ady sÄ… przestarzaÅ‚e

**RozwiÄ…zanie:**
- SprawdÅº nowsze tutoriale na [tensorflow.org/tutorials](https://tensorflow.org/tutorials)
- Zobacz oficjalne [TensorFlow examples repository](https://github.com/tensorflow/examples)
- Korzystaj z dokumentacji Python API (lepiej utrzymana)

### Problem: ChcÄ™ wiÄ™cej przykÅ‚adÃ³w

**Zasoby:**
- [TensorFlow Hub](https://tfhub.dev/) - Gotowe modele
- [TensorFlow Model Garden](https://github.com/tensorflow/models) - Oficjalne implementacje
- [Papers with Code](https://paperswithcode.com/) - Implementacje z paper'Ã³w

## Dalsze kroki

### Po opanowaniu podstaw:

1. **Eksperymentuj** 
   - Modyfikuj parametry
   - Testuj rÃ³Å¼ne architektury
   - PrÃ³buj wÅ‚asnych pomysÅ‚Ã³w

2. **Buduj projekty**
   - Zacznij od prostych
   - Stopniowo zwiÄ™kszaj zÅ‚oÅ¼onoÅ›Ä‡
   - Dokumentuj swÃ³j kod

3. **Dziel siÄ™ wiedzÄ…**
   - PomÃ³Å¼ innym studentom
   - Publikuj swoje projekty
   - Contribute do open source

4. **Naucz siÄ™ wiÄ™cej**
   - Kursy online
   - Czytaj paper'y
   - Uczestnictwo w konferencjach

## Dodatkowe zasoby edukacyjne

### Przewodniki w tym repozytorium (PL)
- ğŸ“˜ [README_PL.md](../README_PL.md) - GÅ‚Ã³wny przewodnik TensorFlow
- ğŸ¤– [UNITREE_G1_GUIDE_PL.md](../UNITREE_G1_GUIDE_PL.md) - Przewodnik dla robota G1
- ğŸ”§ [ROBOTICS_APPLICATIONS_PL.md](../ROBOTICS_APPLICATIONS_PL.md) - Zastosowania w robotyce

### Kursy online
- [TensorFlow w praktyce](https://www.coursera.org/specializations/tensorflow-in-practice)
- [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)
- [Fast.ai](https://www.fast.ai/) - Praktyczne podejÅ›cie do DL

### SpoÅ‚ecznoÅ›ci
- [TensorFlow Forum](https://discuss.tensorflow.org/)
- [r/MachineLearning](https://reddit.com/r/MachineLearning)
- [r/robotics](https://reddit.com/r/robotics)

## Podsumowanie

PrzykÅ‚ady w tym katalogu to:
- âœ… Åšwietny punkt startowy do nauki TensorFlow
- âœ… Demonstracja praktycznych zastosowaÅ„
- âœ… Baza dla projektÃ³w z robotem Unitree G1
- âš ï¸ MogÄ… byÄ‡ przestarzaÅ‚e (preferuj Python API)

**NajwaÅ¼niejsze przykÅ‚ady dla robotyki:**
1. ğŸ¥‡ **label_image** - Rozpoznawanie obiektÃ³w
2. ğŸ¥ˆ **speech_commands** - Sterowanie gÅ‚osowe
3. ğŸ¥‰ **image_retraining** - Dostosowanie modeli

**NastÄ™pne kroki:**
1. PrzejdÅº przez `label_image/README_PL.md`
2. Uruchom przykÅ‚ady na wÅ‚asnych danych
3. Zobacz `UNITREE_G1_GUIDE_PL.md` dla integracji z robotem

---

**Powodzenia w nauce i projektach! ğŸš€ğŸ¤–**

*Pytania? SprawdÅº [ROBOTICS_APPLICATIONS_PL.md](../ROBOTICS_APPLICATIONS_PL.md) lub [GitHub Issues](https://github.com/tensorflow/tensorflow/issues)*
